{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 730 images belonging to 10 classes.\n",
      "Found 109 images belonging to 10 classes.\n",
      "Epoch 1/50\n",
      "22/22 [==============================] - 18s 806ms/step - loss: 2.3088 - acc: 0.1989 - val_loss: 2.1275 - val_acc: 0.2683\n",
      "Epoch 2/50\n",
      "22/22 [==============================] - 17s 754ms/step - loss: 2.0636 - acc: 0.2510 - val_loss: 1.9558 - val_acc: 0.3226\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - 16s 744ms/step - loss: 1.7238 - acc: 0.4110 - val_loss: 1.6232 - val_acc: 0.4839\n",
      "Epoch 4/50\n",
      "22/22 [==============================] - 16s 743ms/step - loss: 1.4535 - acc: 0.4681 - val_loss: 2.0338 - val_acc: 0.3548\n",
      "Epoch 5/50\n",
      "22/22 [==============================] - 16s 741ms/step - loss: 1.3285 - acc: 0.5426 - val_loss: 1.9356 - val_acc: 0.4780\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - 18s 819ms/step - loss: 1.2491 - acc: 0.5796 - val_loss: 1.7593 - val_acc: 0.5054\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - 18s 828ms/step - loss: 1.2098 - acc: 0.5701 - val_loss: 1.8080 - val_acc: 0.5108\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - 20s 893ms/step - loss: 1.0845 - acc: 0.6377 - val_loss: 1.7149 - val_acc: 0.5376\n",
      "Epoch 9/50\n",
      "22/22 [==============================] - 18s 823ms/step - loss: 1.0176 - acc: 0.6560 - val_loss: 1.5603 - val_acc: 0.5220\n",
      "Epoch 10/50\n",
      "22/22 [==============================] - 18s 797ms/step - loss: 0.9962 - acc: 0.6441 - val_loss: 1.6479 - val_acc: 0.5269\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - 18s 836ms/step - loss: 0.9104 - acc: 0.6863 - val_loss: 1.8257 - val_acc: 0.4785\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - 18s 819ms/step - loss: 0.8408 - acc: 0.7215 - val_loss: 1.7008 - val_acc: 0.5161\n",
      "Epoch 13/50\n",
      "22/22 [==============================] - 17s 773ms/step - loss: 0.8175 - acc: 0.7152 - val_loss: 1.6587 - val_acc: 0.5366\n",
      "Epoch 14/50\n",
      "22/22 [==============================] - 17s 777ms/step - loss: 0.7626 - acc: 0.7528 - val_loss: 1.8056 - val_acc: 0.5430\n",
      "Epoch 15/50\n",
      "22/22 [==============================] - 18s 812ms/step - loss: 0.6878 - acc: 0.7764 - val_loss: 1.9851 - val_acc: 0.4839\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - 18s 829ms/step - loss: 0.7012 - acc: 0.7551 - val_loss: 1.5229 - val_acc: 0.5860\n",
      "Epoch 17/50\n",
      "22/22 [==============================] - 17s 794ms/step - loss: 0.6304 - acc: 0.7889 - val_loss: 1.8297 - val_acc: 0.5122\n",
      "Epoch 18/50\n",
      "22/22 [==============================] - 17s 776ms/step - loss: 0.5875 - acc: 0.8049 - val_loss: 1.6842 - val_acc: 0.5484\n",
      "Epoch 19/50\n",
      "22/22 [==============================] - 18s 801ms/step - loss: 0.5499 - acc: 0.8066 - val_loss: 1.9492 - val_acc: 0.4624\n",
      "Epoch 20/50\n",
      "22/22 [==============================] - 17s 753ms/step - loss: 0.6139 - acc: 0.7820 - val_loss: 1.8688 - val_acc: 0.5269\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - 16s 741ms/step - loss: 0.5126 - acc: 0.8300 - val_loss: 1.9593 - val_acc: 0.5561\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - 17s 778ms/step - loss: 0.4605 - acc: 0.8450 - val_loss: 1.8748 - val_acc: 0.5108\n",
      "Epoch 23/50\n",
      "22/22 [==============================] - 17s 759ms/step - loss: 0.4920 - acc: 0.8364 - val_loss: 1.9954 - val_acc: 0.5538\n",
      "Epoch 24/50\n",
      "22/22 [==============================] - 17s 766ms/step - loss: 0.4371 - acc: 0.8494 - val_loss: 1.9837 - val_acc: 0.5323\n",
      "Epoch 25/50\n",
      "22/22 [==============================] - 18s 809ms/step - loss: 0.4140 - acc: 0.8666 - val_loss: 1.8868 - val_acc: 0.5366\n",
      "Epoch 26/50\n",
      "22/22 [==============================] - 19s 853ms/step - loss: 0.4044 - acc: 0.8748 - val_loss: 2.0846 - val_acc: 0.5430\n",
      "Epoch 27/50\n",
      "22/22 [==============================] - 18s 818ms/step - loss: 0.3516 - acc: 0.8950 - val_loss: 2.0009 - val_acc: 0.5645\n",
      "Epoch 28/50\n",
      "22/22 [==============================] - 17s 774ms/step - loss: 0.3577 - acc: 0.8808 - val_loss: 2.1523 - val_acc: 0.5376\n",
      "Epoch 29/50\n",
      "22/22 [==============================] - 18s 801ms/step - loss: 0.3378 - acc: 0.8956 - val_loss: 2.1133 - val_acc: 0.5317\n",
      "Epoch 30/50\n",
      "22/22 [==============================] - 19s 860ms/step - loss: 0.3283 - acc: 0.9084 - val_loss: 2.2178 - val_acc: 0.5430\n",
      "Epoch 31/50\n",
      "22/22 [==============================] - 17s 757ms/step - loss: 0.3267 - acc: 0.8953 - val_loss: 2.2441 - val_acc: 0.5323\n",
      "Epoch 32/50\n",
      "22/22 [==============================] - 18s 798ms/step - loss: 0.3393 - acc: 0.8953 - val_loss: 2.0666 - val_acc: 0.5806\n",
      "Epoch 33/50\n",
      "22/22 [==============================] - 16s 748ms/step - loss: 0.2606 - acc: 0.9027 - val_loss: 1.9990 - val_acc: 0.5756\n",
      "Epoch 34/50\n",
      "22/22 [==============================] - 18s 812ms/step - loss: 0.2229 - acc: 0.9351 - val_loss: 2.2199 - val_acc: 0.5860\n",
      "Epoch 35/50\n",
      "22/22 [==============================] - 16s 712ms/step - loss: 0.2490 - acc: 0.9230 - val_loss: 2.0856 - val_acc: 0.5753\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - 18s 833ms/step - loss: 0.2173 - acc: 0.9301 - val_loss: 2.6569 - val_acc: 0.5215\n",
      "Epoch 37/50\n",
      "22/22 [==============================] - 17s 761ms/step - loss: 0.2501 - acc: 0.9155 - val_loss: 2.2214 - val_acc: 0.5659\n",
      "Epoch 38/50\n",
      "22/22 [==============================] - 17s 785ms/step - loss: 0.2052 - acc: 0.9391 - val_loss: 2.3880 - val_acc: 0.5538\n",
      "Epoch 39/50\n",
      "22/22 [==============================] - 18s 838ms/step - loss: 0.2222 - acc: 0.9332 - val_loss: 2.1496 - val_acc: 0.5914\n",
      "Epoch 40/50\n",
      "22/22 [==============================] - 16s 737ms/step - loss: 0.2254 - acc: 0.9231 - val_loss: 2.5609 - val_acc: 0.5645\n",
      "Epoch 41/50\n",
      "22/22 [==============================] - 16s 739ms/step - loss: 0.2335 - acc: 0.9309 - val_loss: 2.1557 - val_acc: 0.5707\n",
      "Epoch 42/50\n",
      "22/22 [==============================] - 16s 732ms/step - loss: 0.2191 - acc: 0.9315 - val_loss: 2.6159 - val_acc: 0.5000\n",
      "Epoch 43/50\n",
      "22/22 [==============================] - 17s 795ms/step - loss: 0.1888 - acc: 0.9340 - val_loss: 2.0679 - val_acc: 0.5968\n",
      "Epoch 44/50\n",
      "22/22 [==============================] - 17s 764ms/step - loss: 0.2135 - acc: 0.9286 - val_loss: 2.3374 - val_acc: 0.5430\n",
      "Epoch 45/50\n",
      "22/22 [==============================] - 16s 748ms/step - loss: 0.1839 - acc: 0.9411 - val_loss: 2.1628 - val_acc: 0.5659\n",
      "Epoch 46/50\n",
      "22/22 [==============================] - 19s 862ms/step - loss: 0.1569 - acc: 0.9571 - val_loss: 2.0160 - val_acc: 0.5968\n",
      "Epoch 47/50\n",
      "22/22 [==============================] - 19s 855ms/step - loss: 0.1502 - acc: 0.9460 - val_loss: 2.7643 - val_acc: 0.5484\n",
      "Epoch 48/50\n",
      "22/22 [==============================] - 17s 782ms/step - loss: 0.1901 - acc: 0.9304 - val_loss: 2.3707 - val_acc: 0.5215\n",
      "Epoch 49/50\n",
      "22/22 [==============================] - 18s 805ms/step - loss: 0.1486 - acc: 0.9500 - val_loss: 2.2512 - val_acc: 0.5805\n",
      "Epoch 50/50\n",
      "22/22 [==============================] - 17s 764ms/step - loss: 0.1320 - acc: 0.9547 - val_loss: 2.7630 - val_acc: 0.5591\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import h5py\n",
    "\n",
    "#creating a sequential and building a cnn \n",
    "clf = Sequential()\n",
    "\n",
    "# using basic image preprocessing for flattening and using mx pool\n",
    "clf.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "clf.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "clf.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "clf.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "clf.add(Flatten())\n",
    "clf.add(Dense(units = 128, activation = 'relu'))\n",
    "clf.add(Dense(units = 10, activation = 'softmax')) \n",
    "\n",
    "clf.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   rotation_range = 20,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:/Users/dojha/yogapose/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:/Users/dojha/yogapose/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "clf.fit_generator(training_set,\n",
    "                         steps_per_epoch = 729 // batch_size, # number of training set images, 729\n",
    "                         epochs = 50,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 229 // batch_size) # number of test set images, 229\n",
    "\n",
    "\n",
    "clf.save('my_model_multiclass10.h5') #save model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
